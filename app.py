from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage,TemplateSendMessage,MessageAction,CarouselColumn,CarouselTemplate,TextSendMessage,FlexSendMessage
from openai import OpenAI
import numpy as np
import faiss,os,re,time,random

app = Flask(__name__)

language="ç¹é«”ä¸­æ–‡" #èªè¨€è¨­å®š
gpt5_models = ["gpt-5-nano","gpt-4o-mini","gpt-5-mini"]  #GPTæ¨¡å‹
flex_color = [["#F9FAFB","#2563EB","#1F2937"],["#FFF8F0","#E07A5F","#374151"],["#ECFDF5","#10B981","#064E3B"]] # Flexé¡è‰²è¨­å®š

# ä½ çš„ LINE Bot Token
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY") #GPT API

client = OpenAI(api_key=OPENAI_API_KEY) #åˆå§‹åŒ–GPT
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN) #åˆå§‹åŒ–Line bot
handler = WebhookHandler(LINE_CHANNEL_SECRET) #Lineé©—è­‰é‡‘é‘°


#å°‡FAQ.TXTæ ¼å¼åŒ–ï¼Œä»¥\nç‚ºæ–·é»ä¸¦å»ç·¨è™Ÿ
def chunk_text(text):
    '''
    å°‡FAQæ¯è¡Œåˆ†å¥½æ®µè½text.split("\n")ã€‚ä¸¦ç”¨if p.strip()é˜²å‘†ï¼Œè·³éç©ºç™½è¡Œ
    å°‡å„è¡Œé€²ä¸€æ­¥åŠ å·¥^\d+\.\s* åˆªé™¤æ¯è¡Œé–‹é ­(^)çš„å¤šå€‹æ•¸å­—(\d+)åŠå°æ•¸é»(\.)
    '''
    return [re.sub(r'^\d+\.', '', p) for p in text.split("\n") if p.strip()]


# --- è®€å–æœ¬åœ° FAQ.txt
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
faq_path = os.path.join(BASE_DIR, "FAQ.txt")
with open(faq_path, "r", encoding="utf-8") as f:
    faq_text = f.read()


# --- å›æ‡‰åˆ†æ®µè™•ç†
chunks = []
metadata_list = []
for i, chunk in enumerate(chunk_text(faq_text)):
    chunks.append(chunk)
    metadata_list.append({"doc_id": "FAQ", "chunk_index": i+1})


# ---  å« embedding API
embeddings = []
batch_size = 16
for i in range(0, len(chunks), batch_size):
    batch = chunks[i:i+batch_size]
    resp = client.embeddings.create(model="text-embedding-3-small", input=batch)
    for item in resp.data:
        embeddings.append(item.embedding)


# ---  å»ºç«‹ FAISS index
emb_array = np.array(embeddings).astype("float32")
faiss.normalize_L2(emb_array)
dim = emb_array.shape[1]
index = faiss.IndexFlatIP(dim)
index.add(emb_array)


# å°ç…§è¡¨
id_to_meta = {i: metadata_list[i] for i in range(len(metadata_list))} #ä¾†æº
id_to_text = {i: chunks[i] for i in range(len(chunks))} #å…§å®¹


# LINE webhook å…¥å£
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# ä»¥ä¸Šåˆå§‹åŒ–ç¨‹å¼


#ä½¿ç”¨è€…å•é¡ŒæŸ¥è©¢
def query(q_text, k=5, threshold=0.4):
    # å–å¾—ä½¿ç”¨è€…å•é¡Œçš„ embedding
    q_emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=q_text
    ).data[0].embedding

    # è½‰æˆ numpy array ä¸¦ normalize
    q_arr = np.array([q_emb]).astype("float32")
    faiss.normalize_L2(q_arr)

    # åœ¨ FAISS index æœå°‹å‰ k å€‹æœ€ç›¸ä¼¼å‘é‡
    D, I = index.search(q_arr, k)

    results = []
    for score, idx in zip(D[0], I[0]):
        idx = int(idx)
        # éæ¿¾æ‰ç„¡æ•ˆç´¢å¼•æˆ–ç›¸ä¼¼åº¦ä½æ–¼ threshold çš„ç‰‡æ®µ
        if idx == -1 or score < threshold:
            continue

        results.append({
            "text": id_to_text[idx],
            "meta": id_to_meta[idx],
            "score": score
        })

    return results


# ç¢ºèªè¨Šæ¯æ˜¯å¦æ˜¯é›»è©±ç›¸é—œè¨Šæ¯
def phone(text):
    ph1=[]
    ph1.append(re.search(r"03-\d{7}", text).group())
    start = text.find(ph1[0])
    left = text.rfind("â€¢", 0, start)+1 # å¾€å‰æ‰¾æœ€è¿‘çš„åˆ†éš”ç¬¦ â€¢
    ph1.append(text[left:start-1])
    return ph1


# è¨Šæ¯äº‹ä»¶è™•ç†
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):

    #æ–¹ä¾¿å¾ŒçºŒæ•´ç†
    global language #æ²’ä»€éº¼ç”¨ å…¨åŸŸè®Šæ•¸å®£å‘Š
    timen={} #ç¨‹å¼é‹è¡Œæ™‚é–“è»¸ debugç”¨çš„
    start_time = time.time() #ç´€éŒ„èµ·å§‹æ™‚é–“ debugç”¨çš„
    msg = event.message.text #æ–¹ä¾¿å¾ŒçºŒç®¡ç†


    if msg:

        #åªå–5å€‹ç›¸ä¼¼åº¦å¤§æ–¼ 0.4 çš„ç‰‡æ®µ
        retrieved = query(msg, k=5, threshold=0.4)  
        timen["å•é¡Œæ¯”å°"]= time.time() - start_time #æ™‚é–“ç´€éŒ„ debugç”¨çš„

        # ç¢ºèªçµ¦GPTçš„å›æ‡‰çš„æ ¼å¼
        if retrieved: #æœ‰FAQè³‡è¨Š

            context = "\n\n---\n\n".join(f"{r['text']}" for r in retrieved)

            prompt = f"""ä½ æ˜¯ä¸€å€‹å…ƒåŸ¹æ©Ÿå™¨äººã€ä»£è¡¨å…ƒåŸ¹é†«äº‹ç§‘æŠ€å¤§å­¸ã€‚è«‹åŸºæ–¼ä»¥ä¸‹å¼•ç”¨çš„æ–‡ä»¶ç‰‡æ®µå›ç­”ä½¿ç”¨è€…å•é¡Œï¼Œè‹¥èˆ‡å­¸æ ¡ç›¸é—œä¸”ç„¡ç›¸é—œè³‡æ–™è«‹èªªã€Œæ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€ã€‚
            å¼•ç”¨:
            {context}

            ä½¿ç”¨è€…å•é¡Œ: {msg}
            è«‹ç”¨{language}ä»¥åŠæœ€ç²¾æº–ä¸”ç°¡çŸ­ä¸¦ä»¥æœ€å¿«çš„é€Ÿåº¦å›å¾©ã€‚ä½¿ç”¨ã€Œâ€¢ã€ä½œç‚ºå‰ç¶´"""

            
            test = "\n---\n".join(f"[ä¾†æº: {r['meta']['chunk_index']}] {r['text']} [ç›¸ä¼¼åº¦: {r['score']}]" for r in retrieved)
            print("å›æ‡‰:",test) #å¾Œå°ç¢ºèªå‚³çµ¦GPTè³‡æ–™ debugç”¨çš„

        else: #ç„¡FAQè³‡è¨Š GPTè‡ªå·±åˆ¤æ–·æ€éº¼å›
            prompt = f"""ä½ æ˜¯ä¸€å€‹å…ƒåŸ¹æ©Ÿå™¨äººã€ä»£è¡¨å…ƒåŸ¹é†«äº‹ç§‘æŠ€å¤§å­¸ã€‚è«‹å›ç­”ä½¿ç”¨è€…å•é¡Œï¼Œä½†å¦‚æœèˆ‡å­¸æ ¡ç›¸é—œï¼Œè«‹å…ˆå¼•å°è®“ä½¿ç”¨çŸ¥é“æ€éº¼å•æ›´åŠ ç²¾æº–ã€‚è‹¥ç„¡æ³•å¼•å°è«‹å›ã€Œæ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€ã€‚
            ä½¿ç”¨è€…å•é¡Œ: {msg}
            è«‹ç”¨{language}ä»¥åŠæœ€ç²¾æº–ä¸”ç°¡çŸ­ä¸¦ä»¥æœ€å¿«çš„é€Ÿåº¦å›å¾©ã€‚ä½¿ç”¨ã€Œâ€¢ã€ä½œç‚ºå‰ç¶´"""


        timen["å›ç­”æ–¹å¼é¸æ“‡"]= time.time() - start_time #æ™‚é–“ç´€éŒ„
        resp = None

        #ä¾åºåŸ·è¡ŒGPTæ¨¡å‹
        for model_name in gpt5_models:
            try:
                resp = client.responses.create(model=model_name, input=prompt) # å‘¼å«GPT
                print("GPTå‹è™Ÿ:",model_name)
                break
            except Exception as e:
                print(f"{model_name} å‘¼å«å¤±æ•—: {e}")
                time.sleep(0.1)
                continue  #å˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹


        timen["GPTå›ç­”"]= time.time() - start_time
        if resp is None:

            # æ‰€æœ‰æ¨¡å‹éƒ½å¤±æ•—ï¼Œå›å‚³é è¨­è¨Šæ¯
            print("GPTå…¨æ•…éšœï¼Œè«‹æª¢æŸ¥æ˜¯å¦TPD OR APIå‡ºå•é¡Œ")
            line_bot_api.reply_message(event.reply_token, "ç›®å‰ç„¡æ³•å–å¾—å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")

        else:

            rdcolor=random.randint(0,2) # éš¨æ©Ÿè‰²ç³»

            if resp.output_text.count("03-")==1 and "é›»è©±" in resp.output_text: # ç¢ºèªæ˜¯å¦éœ€è¦å‡ºç¾é›»è©±çš„æŒ‰éˆ•

                ph=phone(resp.output_text)
                flex_message = FlexSendMessage(
                    alt_text="å…ƒåŸ¹è³‡ç®¡æ©Ÿå™¨äºº",
                    contents={
                        "type": "bubble",
                        "body": {
                            "type": "box",
                            "layout": "vertical",
                            "backgroundColor": flex_color[rdcolor][0],
                            "contents": [
                                {
                                    "type": "text",
                                    "text": "å…ƒåŸ¹è³‡ç®¡æ©Ÿå™¨äºº",
                                    "weight": "bold",
                                    "size": "xl",
                                    "align": "center",
                                    "color": flex_color[rdcolor][1]
                                },
                                {
                                        "type": "separator",
                                        "margin": "md",
                                },
                                {
                                    "type": "text",
                                    "text": resp.output_text,
                                    "wrap": True,
                                    "size": "sm",
                                    "align": "start",
                                    "color": flex_color[rdcolor][2],
                                    "margin": "md"
                                }
                            ]
                        },"footer": {
                            "type": "box",
                            "layout": "vertical",
                            "spacing": "sm",
                            "backgroundColor": flex_color[rdcolor][0],
                            "contents": [
                                {
                                    "type": "button",
                                    "style": "link",
                                    "action": {
                                        "type": "uri",
                                        "label": f"ğŸ“ è¯çµ¡{ph[1]}",
                                        "uri": f"tel://{ph[0]}"
                                    }
                                }
                            ]
                        }
                    }
                )

            else:

                flex_message = FlexSendMessage(
                    alt_text="å…ƒåŸ¹è³‡ç®¡æ©Ÿå™¨äºº",
                    contents={
                        "type": "bubble",
                        "body": {
                                    "type": "box",
                                    "layout": "vertical",
                                    "backgroundColor":flex_color[rdcolor][0] ,
                                    "contents": [
                                {
                                    "type": "text",
                                    "text": "å…ƒåŸ¹è³‡ç®¡æ©Ÿå™¨äºº",
                                    "weight": "bold",
                                    "size": "xl",
                                    "align": "center",
                                    "color": flex_color[rdcolor][1]  
                                },
                                {
                                    "type": "separator",
                                    "margin": "md",
                                    "color": "#000000"
                                },
                                {
                                    "type": "text",
                                    "text": resp.output_text,
                                    "wrap": True,
                                    "size": "sm",
                                    "align": "start",
                                    "color": flex_color[rdcolor][2],
                                    "margin": "md"
                                }
                            ]
                        }
                    }
                )

            line_bot_api.reply_message(event.reply_token, flex_message) # å°‡è¨Šæ¯å›å‚³

            #å¾Œå°é‹è¡Œé€Ÿåº¦ç´€éŒ„
            timen["LINEæ©Ÿå™¨äººå›å¾©"]= time.time() - start_time
            for i in timen.keys():
                print(i,":",timen[i],end=" ")
            print("")

# è®“ç¨‹å¼åœ¨é€šè¨ŠåŸ 5000é‹è¡Œ
if __name__ == "__main__":
    app.run(port=5000)
